{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import implicit\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "import pickle\n",
    "n = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ndcg_calculator(gt, rec, idcg):\n",
    "    dcg = 0.0\n",
    "    for i, r in enumerate(rec):\n",
    "        if r in gt:\n",
    "            dcg += 1.0 / np.log(i + 2)\n",
    "    return dcg / idcg\n",
    "\n",
    "def ndcg_calculator(answer, submission, n):\n",
    "    idcg = sum((1.0 / np.log(i + 1) for i in range(1, n + 1)))\n",
    "\n",
    "    assert (answer.profile_id != submission.profile_id).sum() == 0\n",
    "\n",
    "    ndcg_list = []\n",
    "    for (_, row_answer), (_, row_submit) in zip(answer.iterrows(), submission.iterrows()):\n",
    "        ndcg_list.append(_ndcg_calculator(row_answer.album_id, row_submit.album_id, idcg))\n",
    "\n",
    "    ndcg_score = sum(ndcg_list) / len(answer)\n",
    "    return ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./data/train.csv\")\n",
    "train_data_answer = train_data[[\"Book-Rating\"]]\n",
    "\n",
    "test_data = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "sample_sumbission = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "\n",
    "train_df = train_data.copy()\n",
    "mf_sumbission = sample_sumbission.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_USERS = train_df['User-ID'].unique().tolist()\n",
    "ALL_ITEMS = train_df['Book-ID'].unique().tolist()\n",
    "\n",
    "user_ids = dict(list(enumerate(ALL_USERS)))\n",
    "item_ids = dict(list(enumerate(ALL_ITEMS)))\n",
    "\n",
    "user_map = {u: uidx for uidx, u in user_ids.items()}\n",
    "item_map = {i: iidx for iidx, i in item_ids.items()}\n",
    "\n",
    "train_df['User-ID'] = train_df['User-ID'].map(user_map)\n",
    "train_df['Book-ID'] = train_df['Book-ID'].map(item_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = train_df['User-ID'].values\n",
    "col = train_df['Book-ID'].values\n",
    "data = np.ones(train_df.shape[0])\n",
    "csr_train = csr_matrix((data, (row, col)), shape=(len(ALL_USERS), len(ALL_ITEMS)))\n",
    "csr_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(csr_train, factors=200, iterations=3, regularization=0.05, show_progress=True):\n",
    "    model = implicit.als.AlternatingLeastSquares(factors=factors, \n",
    "                                                 iterations=iterations, \n",
    "                                                 regularization=regularization, \n",
    "                                                 random_state=42)\n",
    "    model.fit(csr_train, show_progress=show_progress)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(model, csr_train, mf_sumbission):  #default week_train set\n",
    "    preds = []\n",
    "    batch_size = 2000\n",
    "    to_generate = np.arange(len(ALL_USERS))\n",
    "    pred_df = []\n",
    "    for startidx in range(0, len(to_generate), batch_size):\n",
    "        batch = to_generate[startidx : startidx + batch_size]\n",
    "        ids, scores = model.recommend(batch, csr_train[batch], N=25, filter_already_liked_items=False)\n",
    "        for i, profile_id in enumerate(batch):\n",
    "            profile_id = user_ids[profile_id]\n",
    "            user_items = ids[i]\n",
    "            album_ids = [item_ids[item_id] for item_id in user_items] #\n",
    "            pred_df.append({'User-ID':profile_id,'Book-ID':album_ids})\n",
    "            \n",
    "    pred_dfs = pd.DataFrame(pred_df)\n",
    "#     sample_sumbission_week.drop(columns='album_id', inplace=True)\n",
    "    sumbission = mf_sumbission.merge(pred_dfs, on='ID')\n",
    "    \n",
    "    return sumbission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(csr_train, factors=200, iterations=3, regularization=0.05, show_progress=True):\n",
    "    model = implicit.als.AlternatingLeastSquares(factors=factors, \n",
    "                                                 iterations=iterations, \n",
    "                                                 regularization=regularization, \n",
    "                                                 random_state=42)\n",
    "    model.fit(csr_train, show_progress=show_progress)\n",
    "    df_preds = submit(model, csr_train, mf_sumbission)\n",
    "    ndcg = ndcg_calculator(train_data_answer, df_preds, n)\n",
    "#     ndcg = ndcg_calculator(test_answer_week, sample_sumbission_week, n=25)  # submission 여기서 저장 안되어서 정의 불가능 \n",
    "    print(f\"Factors: {factors:>3} - Iterations: {iterations:>2} - Regularization: {regularization:4.3f} ==> ndcg@25: {ndcg:6.5f}\")\n",
    "    return ndcg\n",
    "\n",
    "# df_preds = submit(model, csr_train, sample_sumbission_week)\n",
    "# mf_week_ndcg = ndcg_calculator(test_answer_week, df_preds, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_ndcg25 = 0\n",
    "for factors in [30, 50, 100, 200, 500, 1000]:\n",
    "    for iterations in [3, 5, 10, 15, 20]:\n",
    "        for regularization in [0.01, 0.02, 0.05, 0.1]:\n",
    "            ndcg25 = validate(csr_train, factors, iterations, regularization, show_progress=False)\n",
    "            if ndcg25 > best_ndcg25:\n",
    "                best_ndcg25 = ndcg25\n",
    "                best_params = {'factors': factors, 'iterations': iterations, 'regularization': regularization}\n",
    "                print(f\"Best ndcg@25 found. Updating: {best_params}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
