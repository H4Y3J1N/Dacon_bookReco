{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Dataset, DataLoader\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import SAGEConv, GAE\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = data[['User-ID', 'Age']].drop_duplicates().reset_index(drop=True)\n",
    "books = data[['Book-ID', 'Year-Of-Publication']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "user_id_map = {user_id: idx for idx, user_id in enumerate(users['User-ID'].unique())}\n",
    "book_id_map = {book_id: idx for idx, book_id in enumerate(books['Book-ID'].unique())}\n",
    "\n",
    "users['User-ID'] = users['User-ID'].map(user_id_map)\n",
    "books['Book-ID'] = books['Book-ID'].map(book_id_map)\n",
    "\n",
    "users['Age'] = (users['Age'] - users['Age'].min()) / (users['Age'].max() - users['Age'].min())\n",
    "books['Year-Of-Publication'] = (books['Year-Of-Publication'] - books['Year-Of-Publication'].min()) / (books['Year-Of-Publication'].max() - books['Year-Of-Publication'].min())\n",
    "\n",
    "data['User-ID'] = data['User-ID'].map(user_id_map)\n",
    "data['Book-ID'] = data['Book-ID'].map(book_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed = data.copy()\n",
    "\n",
    "users_dict = users.set_index('User-ID')['Age'].to_dict()\n",
    "books_dict = books.set_index('Book-ID')['Year-Of-Publication'].to_dict()\n",
    "data_processed['User-Age'] = data_processed['User-ID'].apply(lambda x: users_dict[x])\n",
    "data_processed['Book-Year-Of-Publication'] = data_processed['Book-ID'].apply(lambda x: books_dict[x])\n",
    "\n",
    "node_features = torch.tensor(pd.concat([users['Age'], books['Year-Of-Publication']]).values, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "edges = data_processed[['User-ID', 'Book-ID', 'Book-Rating']].copy()\n",
    "user_ids = edges['User-ID'].unique()\n",
    "book_ids = edges['Book-ID'].unique()\n",
    "user_id_map = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "book_id_map = {book_id: idx + len(user_ids) for idx, book_id in enumerate(book_ids)}\n",
    "edges['User-ID'] = edges['User-ID'].map(user_id_map)\n",
    "edges['Book-ID'] = edges['Book-ID'].map(book_id_map)\n",
    "\n",
    "edge_index = torch.tensor(edges[['User-ID', 'Book-ID']].values, dtype=torch.long).t().contiguous()\n",
    "edge_attr = torch.tensor(edges['Book-Rating'].values, dtype=torch.float).unsqueeze(-1)\n",
    "\n",
    "target = torch.tensor(data_processed['Book-Rating'].values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of rows in data_processed: {len(data_processed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookRatingData(Dataset):\n",
    "    def __init__(self, node_features, edge_index, edge_attr, target):\n",
    "        super(BookRatingData, self).__init__()\n",
    "        self.node_features = node_features\n",
    "        self.edge_index = edge_index\n",
    "        self.edge_attr = edge_attr\n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.edge_index.size(1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'x': self.node_features,\n",
    "            'edge_index': self.edge_index,\n",
    "            'edge_attr': self.edge_attr,\n",
    "            'y': self.target[idx]\n",
    "        }\n",
    "\n",
    "book_rating_data = BookRatingData(node_features, edge_index, edge_attr, target)\n",
    "\n",
    "def split_edges(dataset, split_ratio=(0.8, 0.2)):\n",
    "    num_edges = len(dataset)\n",
    "    indices = list(range(num_edges))\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    split_idx = int(split_ratio[0] * num_edges)\n",
    "    train_indices, test_indices = indices[:split_idx], indices[split_idx:]\n",
    "\n",
    "    return [dataset[i] for i in train_indices], [dataset[i] for i in test_indices]\n",
    "\n",
    "train_dataset, test_dataset = split_edges(book_rating_data)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
