{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Dataset, DataLoader\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import SAGEConv, GAE\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, user_id_map=None, book_id_map=None, age_min=None, age_max=None, year_min=None, year_max=None):\n",
    "    data = data.copy()\n",
    "\n",
    "    users = data[['User-ID', 'Age']].drop_duplicates().reset_index(drop=True)\n",
    "    books = data[['Book-ID', 'Year-Of-Publication']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    if user_id_map is None:\n",
    "        user_id_map = {user_id: idx for idx, user_id in enumerate(users['User-ID'].unique())}\n",
    "    if book_id_map is None:\n",
    "        book_id_map = {book_id: idx for idx, book_id in enumerate(books['Book-ID'].unique())}\n",
    "\n",
    "    if age_min is None:\n",
    "        age_min = users['Age'].min()\n",
    "        age_max = users['Age'].max()\n",
    "    if year_min is None:\n",
    "        year_min = books['Year-Of-Publication'].min()\n",
    "        year_max = books['Year-Of-Publication'].max()\n",
    "\n",
    "    users['Age'] = (users['Age'] - age_min) / (age_max - age_min)\n",
    "    books['Year-Of-Publication'] = (books['Year-Of-Publication'] - year_min) / (year_max - year_min)\n",
    "\n",
    "    data = data.merge(users, on='User-ID', suffixes=('', '_updated'))\n",
    "    data = data.merge(books, on='Book-ID', suffixes=('', '_updated'))\n",
    "    data = data.drop(columns=['Age', 'Year-Of-Publication'])\n",
    "    data = data.rename(columns={'Age_updated': 'Age', 'Year-Of-Publication_updated': 'Year-Of-Publication'})\n",
    "    \n",
    "    data['User-ID'] = data['User-ID'].map(user_id_map)\n",
    "    data['Book-ID'] = data['Book-ID'].map(book_id_map)\n",
    "    \n",
    "    data_processed = data.fillna(0)\n",
    "\n",
    "    return data_processed, user_id_map, book_id_map, age_min, age_max, year_min, year_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_processed, user_id_map, book_id_map, age_min, age_max, year_min, year_max = preprocess_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = train_data_processed[[\"Age\",\"Year-Of-Publication\"]].to_numpy()\n",
    "edge_index = torch.tensor(train_data_processed[['User-ID', 'Book-ID']].values, dtype=torch.long).t().contiguous()\n",
    "\n",
    "#################################### 더 적합한 것으로 추후 변경\n",
    "edge_attr = torch.tensor(train_data_processed['Book-Rating'].values, dtype=torch.float).unsqueeze(-1)\n",
    "target = torch.tensor(train_data_processed['Book-Rating'].values, dtype=torch.float).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = Data(x=torch.tensor(node_features), edge_index=edge_index, edge_attr=edge_attr, y=target, user_ids=user_ids, item_ids=item_ids)\n",
    "graph_data.n_id = torch.arange(graph_data.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGraphDataset(Dataset):\n",
    "    def __init__(self, data_list, transform=None, pre_transform=None):\n",
    "        super(CustomGraphDataset, self).__init__(None, transform, pre_transform)\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.data_list[idx]\n",
    "    \n",
    "# 데이터셋 생성\n",
    "data_list = [graph_data]  \n",
    "dataset = CustomGraphDataset(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Neighbor Loader\n",
    "# gSAGE_loader = NeighborLoader(\n",
    "#     graph_data,\n",
    "#     num_neighbors=[10,10],\n",
    "#     batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = graph_data.x.shape[1]\n",
    "hidden_channels = 64\n",
    "out_channels = 16\n",
    "embedding_dim = 32\n",
    "user_count = user_count\n",
    "item_count = item_count\n",
    "####################################\n",
    "# 추후 베이지안 최적화(Bayesian optimization)\n",
    "####################################\n",
    "# conv 레이어 개수\n",
    "# 은닉층의 노드 수 (hidden_channels)\n",
    "# 드롭아웃 비율 (dropout rate)\n",
    "# 학습률 (learning rate)\n",
    "# 가중치 감소 (weight decay)\n",
    "# 배치 크기 (batch size)\n",
    "# 최적화 알고리즘 (optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGERatingPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, embedding_dim, user_count, item_count):\n",
    "        super(GraphSAGERatingPredictor, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, embedding_dim)\n",
    "\n",
    "        self.user_embedding = nn.Embedding(user_count, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(item_count, embedding_dim)\n",
    "        self.regressor = nn.Linear(embedding_dim * 2, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, user_ids, item_ids):\n",
    "        x, edge_index = x.float().to(device), edge_index.to(device)        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        user_embeddings = self.user_embedding(user_ids)\n",
    "        item_embeddings = self.item_embedding(item_ids)\n",
    "\n",
    "        concatenated_embeddings = torch.cat((user_embeddings, item_embeddings), dim=1)\n",
    "        rating_predictions = self.regressor(concatenated_embeddings)\n",
    "        return rating_predictions.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GraphSAGE(torch.nn.Module):\n",
    "#     def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "#         super(GraphSAGE, self).__init__()\n",
    "#         self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "#         self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "#     def forward(self, x, edge_index):\n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.dropout(x, p=0.5, training=self.training)\n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         x = F.relu(x)\n",
    "#         return x\n",
    "\n",
    "# model = GraphSAGE(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=out_channels)\n",
    "# model = model.to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.005,weight_decay=1e-5)\n",
    "# loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "# loss_function = torch.nn.MSELoss()\n",
    "\n",
    "# def train(loader):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     for data in tqdm(loader):\n",
    "#         data = data.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         z = model(data.x.float(), data.edge_index)\n",
    "        \n",
    "#         book_ratings = data.y.to(device)\n",
    "        \n",
    "#         loss = loss_function(z, book_ratings)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_loss += loss.item()\n",
    "#     return total_loss / len(loader), model\n",
    "\n",
    "# num_epoch = 100\n",
    "\n",
    "# for epoch in range(0,num_epoch):\n",
    "#     loss,model = train(loader)\n",
    "#     print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n",
    "# torch.save(model,\"base_graphSage_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGERatingPredictor(in_channels, hidden_channels, embedding_dim, user_count, item_count)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "optimizer.load_state_dict(optimizer.state_dict())\n",
    "criterion = nn.MSELoss()\n",
    "criterion = criterion.to(device)\n",
    "loader = DataLoader(dataset, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(loader):\n",
    "        batch_x = batch.x.to(device)\n",
    "        batch_edge_index = batch.edge_index\n",
    "        batch_user_ids = batch.user_ids\n",
    "        batch_item_ids = batch.item_ids\n",
    "        batch_user_ids = torch.tensor(batch_user_ids, dtype=torch.long).to(device)\n",
    "        batch_item_ids = torch.tensor(batch_item_ids, dtype=torch.long).to(device)\n",
    "        batch_y = batch.y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch_x, batch_edge_index, batch_user_ids, batch_item_ids)\n",
    "        out = out.to(device)\n",
    "        loss = criterion(out, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(loader, model, criterion, optimizer)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train User-ID min:\", train_data_processed['User-ID'].min())\n",
    "print(\"train User-ID max:\", train_data_processed['User-ID'].max())\n",
    "print(\"train Book-ID min:\", train_data_processed['Book-ID'].min())\n",
    "print(\"train Book-ID max:\", train_data_processed['Book-ID'].max())\n",
    "\n",
    "print(\"train_node_features shape:\", node_features.shape)\n",
    "print(\"train_edge_index shape:\", edge_index.shape)\n",
    "\n",
    "print(\"train Edge index min:\", data_list[0].edge_index.min())\n",
    "print(\"train Edge index max:\", data_list[0].edge_index.max())\n",
    "\n",
    "print(\"train_graph_data.x shape:\", graph_data.x.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding by mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"base_graphSage_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_embeddings = np.zeros((graph_data.num_nodes,32))\n",
    "np_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "index = AnnoyIndex(32, 'angular')\n",
    "\n",
    "for idx,idx_embedding in enumerate(np_embeddings):\n",
    "    index.add_item(idx, idx_embedding)\n",
    "    \n",
    "index.build(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del np_embeddings\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation / Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
