{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Dataset, DataLoader\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import SAGEConv, GAE\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, user_id_map=None, book_id_map=None, age_min=None, age_max=None, year_min=None, year_max=None):\n",
    "    data = data.copy()\n",
    "\n",
    "    users = data[['User-ID', 'Age']].drop_duplicates().reset_index(drop=True)\n",
    "    books = data[['Book-ID', 'Year-Of-Publication']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    if user_id_map is None:\n",
    "        user_id_map = {user_id: idx for idx, user_id in enumerate(users['User-ID'].unique())}\n",
    "    if book_id_map is None:\n",
    "        book_id_map = {book_id: idx for idx, book_id in enumerate(books['Book-ID'].unique())}\n",
    "\n",
    "    if age_min is None:\n",
    "        age_min = users['Age'].min()\n",
    "        age_max = users['Age'].max()\n",
    "    if year_min is None:\n",
    "        year_min = books['Year-Of-Publication'].min()\n",
    "        year_max = books['Year-Of-Publication'].max()\n",
    "\n",
    "    users['Age'] = (users['Age'] - age_min) / (age_max - age_min)\n",
    "    books['Year-Of-Publication'] = (books['Year-Of-Publication'] - year_min) / (year_max - year_min)\n",
    "\n",
    "    data = data.merge(users, on='User-ID', suffixes=('', '_updated'))\n",
    "    data = data.merge(books, on='Book-ID', suffixes=('', '_updated'))\n",
    "    data = data.drop(columns=['Age', 'Year-Of-Publication'])\n",
    "    data = data.rename(columns={'Age_updated': 'Age', 'Year-Of-Publication_updated': 'Year-Of-Publication'})\n",
    "    \n",
    "    data['User-ID'] = data['User-ID'].map(user_id_map)\n",
    "    data['Book-ID'] = data['Book-ID'].map(book_id_map)\n",
    "    \n",
    "    data_processed = data.fillna(0)\n",
    "\n",
    "    return data_processed, user_id_map, book_id_map, age_min, age_max, year_min, year_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_processed, user_id_map, book_id_map, age_min, age_max, year_min, year_max = preprocess_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = train_data_processed[[\"Age\",\"Year-Of-Publication\"]].to_numpy()\n",
    "edge_index = torch.tensor(train_data_processed[['User-ID', 'Book-ID']].values, dtype=torch.long).t().contiguous()\n",
    "\n",
    "#################################### 더 적합한 것으로 추후 변경\n",
    "edge_attr = torch.tensor(train_data_processed['Book-Rating'].values, dtype=torch.float).unsqueeze(-1)\n",
    "target = torch.tensor(train_data_processed['Book-Rating'].values, dtype=torch.float).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edge_index)\n",
    "print(edge_index.shape)\n",
    "print(f\"Number of rows in data_processed: {len(train_data_processed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = Data(x=torch.tensor(node_features), edge_index=edge_index, edge_attr=edge_attr, y=target)\n",
    "graph_data.n_id = torch.arange(graph_data.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = Data(x=torch.tensor(node_features), edge_index=edge_index, edge_attr=edge_attr, y=target)\n",
    "graph_data.n_id = torch.arange(graph_data.num_nodes)\n",
    "\n",
    "class CustomGraphDataset(Dataset):\n",
    "    def __init__(self, data_list, transform=None, pre_transform=None):\n",
    "        super(CustomGraphDataset, self).__init__(None, transform, pre_transform)\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.data_list[idx]\n",
    "    \n",
    "# 데이터셋 생성\n",
    "data_list = [graph_data]  # 데이터셋에는 graph_data만 포함됩니다.\n",
    "dataset = CustomGraphDataset(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Neighbor Loader\n",
    "# gSAGE_loader = NeighborLoader(\n",
    "#     graph_data,\n",
    "#     num_neighbors=[10,10],\n",
    "#     batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 32\n",
    "hidden_channels = 64\n",
    "out_channels = 1\n",
    "####################################\n",
    "# 추후 베이지안 최적화(Bayesian optimization)\n",
    "####################################\n",
    "# conv 레이어 개수\n",
    "# 은닉층의 노드 수 (hidden_channels)\n",
    "# 드롭아웃 비율 (dropout rate)\n",
    "# 학습률 (learning rate)\n",
    "# 가중치 감소 (weight decay)\n",
    "# 배치 크기 (batch size)\n",
    "# 최적화 알고리즘 (optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=out_channels)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005,weight_decay=1e-5)\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "loss_function = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in tqdm(loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        z = model(data.x.float(), data.edge_index)\n",
    "        \n",
    "        book_ratings = data.y.to(device)\n",
    "        \n",
    "        loss = loss_function(z, book_ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 100\n",
    "\n",
    "for epoch in range(0,num_epoch):\n",
    "    loss,model = train(loader)\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train User-ID min:\", train_data_processed['User-ID'].min())\n",
    "print(\"train User-ID max:\", train_data_processed['User-ID'].max())\n",
    "print(\"train Book-ID min:\", train_data_processed['Book-ID'].min())\n",
    "print(\"train Book-ID max:\", train_data_processed['Book-ID'].max())\n",
    "\n",
    "print(\"train_node_features shape:\", node_features.shape)\n",
    "print(\"train_edge_index shape:\", edge_index.shape)\n",
    "\n",
    "print(\"train Edge index min:\", data_list[0].edge_index.min())\n",
    "print(\"train Edge index max:\", data_list[0].edge_index.max())\n",
    "\n",
    "print(\"train_graph_data.x shape:\", graph_data.x.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
