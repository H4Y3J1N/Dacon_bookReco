{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Dataset, DataLoader\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import SAGEConv, GAE\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = data[['User-ID', 'Age']].drop_duplicates().reset_index(drop=True)\n",
    "books = data[['Book-ID', 'Year-Of-Publication']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "user_id_map = {user_id: idx for idx, user_id in enumerate(users['User-ID'].unique())}\n",
    "book_id_map = {book_id: idx for idx, book_id in enumerate(books['Book-ID'].unique())}\n",
    "\n",
    "data['Age'] = (users['Age'] - users['Age'].min()) / (users['Age'].max() - users['Age'].min())\n",
    "data['Year-Of-Publication'] = (books['Year-Of-Publication'] - books['Year-Of-Publication'].min()) / (books['Year-Of-Publication'].max() - books['Year-Of-Publication'].min())\n",
    "\n",
    "data['User-ID'] = data['User-ID'].map(user_id_map)\n",
    "data['Book-ID'] = data['Book-ID'].map(book_id_map)\n",
    "\n",
    "data_processed = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = data_processed[[\"Age\",\"Year-Of-Publication\"]].to_numpy()\n",
    "edge_index = torch.tensor(data_processed[['User-ID', 'Book-ID']].values, dtype=torch.long).t().contiguous()\n",
    "\n",
    "#################################### 더 적합한 것으로 추후 변경\n",
    "edge_attr = torch.tensor(data_processed['Book-Rating'].values, dtype=torch.float).unsqueeze(-1)\n",
    "\n",
    "target = torch.tensor(data_processed['Book-Rating'].values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edge_index)\n",
    "print(edge_index.shape)\n",
    "print(f\"Number of rows in data_processed: {len(data_processed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graph_data = Data(x=torch.tensor(node_features), edge_index=edge_index, edge_attr=edge_attr)\n",
    "graph_data.n_id = torch.arange(graph_data.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data.edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data.n_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 훈련 및 테스트 데이터로 분할합니다. (예를 들어 80:20 비율)\n",
    "total_data_len = len(graph_data)\n",
    "train_data_len = int(total_data_len * 0.8)\n",
    "test_data_len = total_data_len - train_data_len\n",
    "\n",
    "train_data, test_data = random_split(graph_data, [train_data_len, test_data_len])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=512, shuffle=True, num_workers=6)\n",
    "test_loader = DataLoader(test_data, batch_size=512, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Neighbor Loader\n",
    "# gSAGE_loader = NeighborLoader(\n",
    "#     graph_data,\n",
    "#     num_neighbors=[10,10],\n",
    "#     batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 32\n",
    "hidden_channels = 64\n",
    "out_channels = 1\n",
    "####################################\n",
    "# 추후 베이지안 최적화(Bayesian optimization)\n",
    "####################################\n",
    "# conv 레이어 개수\n",
    "# 은닉층의 노드 수 (hidden_channels)\n",
    "# 드롭아웃 비율 (dropout rate)\n",
    "# 학습률 (learning rate)\n",
    "# 가중치 감소 (weight decay)\n",
    "# 배치 크기 (batch size)\n",
    "# 최적화 알고리즘 (optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=out_channels)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005,weight_decay=1e-5)\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "loss_function = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in tqdm(loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        z = model(data.x.float(), data.edge_index)\n",
    "        \n",
    "        book_ratings = data.y.to(device)\n",
    "        \n",
    "        loss = loss_function(z, book_ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 100\n",
    "\n",
    "for epoch in range(0,num_epoch):\n",
    "    loss,model = train(loader)\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
