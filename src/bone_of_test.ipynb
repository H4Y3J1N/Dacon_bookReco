{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가장 먼저 해야 할 것 : OTTO 데이터셋을 가지고 아래 작업들이 가능하게 세팅하기.\n",
    "### 이게 80%고 나머지는 그냥 고속도로임. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네트워크x로 노드 그래프를 그릴 떄, 노드가 꼭 정수나 알파벳이 아니어도 된다.    \n",
    "\n",
    "둘 다 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음 그래프 그려보기 (무방향 그래프) + Weighted Graph + node degree\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_edges_from()\n",
    "\n",
    "print(f\"def(A) = {G.degree['A']}\") # A는 노드 이름. \n",
    "\n",
    "\n",
    "#예제에선 여기에 직접 (\"A\",\"B\")처럼 다 적어 넣음. \n",
    "# # 하지만 나는 OTTO로 할 수 있는 방법을 찾아내자\n",
    "# Weighted Graph도 이 그래프에 함께 넣는 법 있는지 확인해보기!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방향성 그래프 + degree of nodes (indegree, outdegree)\n",
    "\n",
    "DG = nx.DiGraph()\n",
    "DG.add_edges_from()\n",
    "\n",
    "print(f\"def^-(A) = {DG.in_degree['A']}\") # A는 노드. \n",
    "print(f\"def^+(A) = {DG.out_degree['A']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connected Graphs\n",
    "\n",
    "G1 = nx.Graph()\n",
    "G1.add_edges_from([]) #노드 연결관계 일일히 써넣음\n",
    "\n",
    "print(f\"Is Graph 1 connected? {nx.is_connected(G1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph measures \n",
    "\n",
    "### centrality 중심성 측정 방법 3가지\n",
    "\n",
    "print(f\"Degree centrality = {nx.degree_centrality(G)}\")\n",
    "print(f\"Closeness centrality = {nx.closeness_centrality(G)}\")\n",
    "print(f\"Betweeness centrality = {nx.betweenness_centrality(G)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# density 이야기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjacency matrix 이야기\n",
    "\n",
    "# 튜토리얼에서는 직접 매트릭스를 만들지만, 나는 위에서 만든 그래프를 바로 \n",
    "# 매트릭스로 바꿔주는 메서드가 있는지 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge list\n",
    "## 위 그래프로 출력해보기\n",
    "\n",
    "#adjacency list\n",
    "## 위 그래프로 출력해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random walk\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random \n",
    "random.seed(0)\n",
    "\n",
    "\n",
    "# 책에서는 랜덤한 그래프를 만들지만, 나는 직접 노드 수를 10개 이상으로(책에서 10개함) 제작\n",
    "G = #그래프. directed =False\n",
    "\n",
    "plt.figure(dpi=300)\n",
    "plt.axis(\"off\")\n",
    "nx.draw_networkx(G,\n",
    "                 pos = nx.spring_layout(G, seed = 0),\n",
    "                 node_size = 600,\n",
    "                 cmap = \"coolwarm\",\n",
    "                 font_size = 14,\n",
    "                 font_color = \"white\")\n",
    "\n",
    "# 드디어 랜덤 워크 적용! (함수로 만듦)\n",
    "def random_walk(start,length):\n",
    "    walk = [str(start)] # starting node\n",
    "\n",
    "    for i in range(length):\n",
    "        neighbors = [node for node in G.neighbors(start)]\n",
    "        next_node = np.random.choice(neighbors, 1)[0]\n",
    "        walk.append(str(next_node))\n",
    "        start = next_node\n",
    "    \n",
    "    return walk\n",
    "\n",
    "# 위 함수를 실행해서 랜덤워크 결과 출력해봄. 근데 def로만 가능해? 흠.\n",
    "# 라이브러리로 랜덤 워크 안 되는지 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep walk\n",
    "## Implment DeepWalk <이제 실제  ML 문제를 해결해보자>\n",
    "\n",
    "# -근데 가라테클럽의 노드는 모두 인간. 그들 사이의 관계만 봄(심지어 한쪽 사이드만 확인함). \n",
    "# >>> 다른 데이터셋으로 대체하고싶은데 뭐가 있지? chat에게 물어보자. \n",
    "# \"just by looking at their connections\"\n",
    "# 이 데이터셋엔 라벨도 있는듯?\n",
    "\n",
    "\n",
    "# word2vec + skip gram + H-softmax(혹은 다른 소프트맥스)  개념도 등장\n",
    "# word2vec을 쓰기 위해 randomWalk를 사용했고, \n",
    "# 임베딩을 가지고 유사도를 구한 다음 분류문제를 풀었다.\n",
    "\n",
    "# 코드 순서\n",
    "# word2vec + skip gram + H-softmax(혹은 다른 소프트맥스) \n",
    "# similarity 계산\n",
    "# t-SNE로 임베딩을 플롯팅.\n",
    "# classification모델로 분류해봄. (여기선 랜덤 포레스트 모델 씀)\n",
    "# 마스킹 방법도 가볍게 배움 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path('/kaggle/input/otto-recommender-system/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sessions = pd.DataFrame()\n",
    "chunks = pd.read_json(data_path / 'train.jsonl', lines=True, chunksize=100_000)\n",
    "\n",
    "for e, chunk in enumerate(chunks):\n",
    "    event_dict = {\n",
    "        'session': [],\n",
    "        'aid': [],\n",
    "        'ts': [],\n",
    "        'type': [],\n",
    "    }\n",
    "    if e < 2:\n",
    "        # train_sessions = pd.concat([train_sessions, chunk])\n",
    "        for session, events in zip(chunk['session'].tolist(), chunk['events'].tolist()):\n",
    "            for event in events:\n",
    "                event_dict['session'].append(session)\n",
    "                event_dict['aid'].append(event['aid'])\n",
    "                event_dict['ts'].append(event['ts'])\n",
    "                event_dict['type'].append(event['type'])\n",
    "        chunk_session = pd.DataFrame(event_dict)\n",
    "        train_sessions = pd.concat([train_sessions, chunk_session])\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "train_sessions = train_sessions.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타임스탬프를 날짜와 시간으로 변환합니다.\n",
    "train_sessions['ts'] = pd.to_datetime(train_sessions['ts'], unit='ms')\n",
    "\n",
    "# 'ts' 컬럼에서 날짜만 선택합니다.\n",
    "train_sessions['date'] = train_sessions['ts'].dt.date\n",
    "\n",
    "# 8월 1일에 해당하는 트랜잭션만 선택합니다.\n",
    "# df_aug = train_sessions[train_sessions['date'] == pd.to_datetime('2022-08-01')]\n",
    "\n",
    "# 'type' 열을 사용하여 'orders' 이벤트만 선택합니다.\n",
    "# array(['clicks', 'carts', 'orders'], dtype=object)\n",
    "df_orders = df_aug[df_aug1['type'] == 'orders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
